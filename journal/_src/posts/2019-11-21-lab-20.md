    Title: Lab 20
    Date: 2019-11-21T00:00:00
    Tags: DONE

Bring on Octave!

<!-- more -->

## Running Octave

Lab 20 started off by instructing us on how to run Octave programs. Similar to Racket there are two main ways to run it; through the command line in REPL fashion with `octave`, or through a GUI application similar to DrRacket.

## Fibonacci

What would a lab be without Fibonacci. After learning how to run Octave we looked at creating an Octave program to generate the Fibonacci sequence. Right away there is a big difference between Octave and other programming languages; there are no brackets used. Instead of using brackets to define scope, Octave using keywords such as `endfor` and `endfunction`. Octave also has similar unpacking to Python using the deal function:

```python
a, b = b, a + b
```

is equivalent to

```matlab
[a, b] = deal(b, a + b)
```

We can now write the Fibonacci generator in Octave:

```matlab
function ret = fib(n)
	a = 0;
	b = 1;
	for i=0:n
		ret = a;
		a = a + b;
		b = ret;
	endfor
endfunction

%!assert (fib(0) == 0);
```

After saving the function we can run it in the Octave command line with `>> test fib`.

- Return value is specified by `function ret = fib(n)`
- Semi-colon tells the interpreter not to print the line out.

## Matrix and Vector Review

- Dot product: `dot([1;0;1], [2,1,0])`
- Matrix multiplication: `[1;0;1] * [2,1,0]`

## Fibonacci as Matrix Multiplication

After reviewing basic matrix operations we looked at using matrixes to calculate the Fibonacci sequence. Fibonacci can be easily vectorized with the following.

```
[1,1; 1,0]^n = [
	F(n+1) , F(n);
	F(n), F(n-1)
]
```

One quirk found in this exercise is that Octave indexes from 1. This doesn't complicate things too much but is slightly annoying coming from languages that index at 0. Octave also uses parenthesis to access array and matrix indexies which looks a little odd.

```matlab
function ret = fibmat(n)
	A = [1,1; 1,0];
	B = A^n;
	ret = B(1,2);
endfunction
```

## Performance Comparison

timeit(@fib, 42, 100000)
fib	median=0.280ms mean=0.296ms total=29632.214ms
timeit(@fibmat, 42, 100000)
fibmat	median=0.050ms mean=0.055ms total=5467.865ms

Vectorization is over 5 times faster than iteration.

## Measuring CPU Time

ctimeit(@fib, 42, 100000)
fib	median=0.284ms mean=0.298ms total=29780.736ms
ctimeit(@fibmat, 42, 100000)
fibmat	median=0.053ms mean=0.060ms total=6011.650ms

CPU time is longer than clock time. This is odd. This seems to be because cputime has less precision than clock time and isn't always perfectly synchronized.

## Using the Profiler


The last part of this lab looked at profiling. Profiling improves upon timing by recording the number of calls to each function

```
>>> profile on
>>> profile off
>>> profshow
>>> profile cleaer
```

>> profile on
>> fib(1000)
ans = 4.3467e+208
>> profile off
>> profshow
   #            Function Attr     Time (s)   Time (%)        Calls
------------------------------------------------------------------
   1                 fib             0.008      86.34            1
   4                disp             0.001       6.67            1
   2            binary +             0.001       5.37         1001
   3             display             0.000       0.92            1
   5             profile             0.000       0.59            1
   6              nargin             0.000       0.04            1
   8               false             0.000       0.04            1
   7           binary !=             0.000       0.02            1
   9 __profiler_enable__             0.000       0.00            1

>> profile on
>> fibmat(1000)
ans = 4.3467e+208
>> profshow
   #            Function Attr     Time (s)   Time (%)        Calls
------------------------------------------------------------------
   3             display             0.000      28.09            1
   5             profile             0.000      26.70            1
   1              fibmat             0.000      15.64            1
   2            binary ^             0.000      13.83            1
   4                disp             0.000      10.74            1
   6              nargin             0.000       1.81            1
   8               false             0.000       1.81            1
   7           binary !=             0.000       1.38            1
   9 __profiler_enable__             0.000       0.00            1

Looking at the profiler we can see that the iterative version makes 1001 calls to the binary + operator. This is in comparison to the one call made to the binary ^ in the vectorized implementation. We can clearly see why the vectorized version is faster.

